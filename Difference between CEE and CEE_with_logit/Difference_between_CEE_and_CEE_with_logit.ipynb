{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Difference_between_CEE_and_CEE_with_logit.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOLxVSmbk8NmCO1fy5FLivf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KwEtfeKIXxPh","colab_type":"text"},"source":["김성훈 교수님의 DeepLearningZeroToAll 저장소에 있는 소스코드 중 하나\n","\n","https://github.com/hunkim/DeepLearningZeroToAll/blob/master/tf2/tf2-10-5-mnist_nn_dropout.py\n","\n","를 'model.compile'과 'model.fit' API를 사용하지 않고 커스텀 루프로 학습하도록 바꿔봤더니 수렴속도나 최종 결과물에 엄청난 차이가 있음을 발견하였다.\n","\n","우선 동일한 결과를 보장하기 위해 기본 세팅은 통일한다."]},{"cell_type":"code","metadata":{"id":"Ip6YZH-gXmMc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597319344486,"user_tz":-540,"elapsed":769,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}}},"source":["import tensorflow as tf\n","import random\n","from tensorflow.keras.datasets.mnist import load_data\n","\n","random.seed(777)\n","learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100\n","drop_rate = 0.3"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w9kFOu-dZfjJ","colab_type":"text"},"source":["데이터(MNIST) 준비"]},{"cell_type":"code","metadata":{"id":"i_5wh819YwU-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597319345527,"user_tz":-540,"elapsed":1789,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}}},"source":["(x_train, y_train), (x_test, y_test) = load_data()\n","\n","x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n","x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n","\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OjXLSW6NZLdk","colab_type":"text"},"source":["model.compile과 fit을 사용하는 루프"]},{"cell_type":"code","metadata":{"id":"MMsZDNOKZTnV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"status":"ok","timestamp":1597319559650,"user_tz":-540,"elapsed":215887,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"74407b9d-1141-4da5-af17-a51780183570"},"source":["model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=10, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy',\n","                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","600/600 [==============================] - 14s 23ms/step - loss: 3.2072 - accuracy: 0.7369\n","Epoch 2/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.4223 - accuracy: 0.8828\n","Epoch 3/15\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3021 - accuracy: 0.9151\n","Epoch 4/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.2480 - accuracy: 0.9300\n","Epoch 5/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.2185 - accuracy: 0.9395\n","Epoch 6/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.2006 - accuracy: 0.9451\n","Epoch 7/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.1836 - accuracy: 0.9507\n","Epoch 8/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.1872 - accuracy: 0.9503\n","Epoch 9/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.1758 - accuracy: 0.9543\n","Epoch 10/15\n","600/600 [==============================] - 15s 24ms/step - loss: 0.1842 - accuracy: 0.9539\n","Epoch 11/15\n","600/600 [==============================] - 15s 25ms/step - loss: 0.1778 - accuracy: 0.9557\n","Epoch 12/15\n","600/600 [==============================] - 15s 25ms/step - loss: 0.1736 - accuracy: 0.9568\n","Epoch 13/15\n","600/600 [==============================] - 14s 24ms/step - loss: 0.1726 - accuracy: 0.9587\n","Epoch 14/15\n","600/600 [==============================] - 15s 25ms/step - loss: 0.1810 - accuracy: 0.9578\n","Epoch 15/15\n","600/600 [==============================] - 15s 25ms/step - loss: 0.1727 - accuracy: 0.9597\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z5EuMF39Z6zN","colab_type":"text"},"source":["학습결과를 확인해본다."]},{"cell_type":"code","metadata":{"id":"miS7OzKqZc9_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1597319561413,"user_tz":-540,"elapsed":217352,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"eae5bdaa-bda4-4854-f76b-cc10ae421820"},"source":["evaluation = model.evaluate(x_test, y_test)\n","print('loss: ', evaluation[0])\n","print('accuracy', evaluation[1])"],"execution_count":27,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 2s 5ms/step - loss: 0.1422 - accuracy: 0.9715\n","loss:  0.14218217134475708\n","accuracy 0.9714999794960022\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e2ueETy8aBZ5","colab_type":"text"},"source":["이제 이를 커스텀 루프로 바꾼 뒤 다시 학습시켜본다. \n","\n","데이터로더를 커스텀 루프에 맞게 정의한다."]},{"cell_type":"code","metadata":{"id":"0--2murYaV6x","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597319561990,"user_tz":-540,"elapsed":217908,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}}},"source":["(x_train, y_train), (x_test, y_test) = load_data()\n","\n","x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n","x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n","\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","\n","data_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLtjwk1FbOFZ","colab_type":"text"},"source":["model.compile과 fit을 사용하지 않는 커스텀 루프"]},{"cell_type":"code","metadata":{"id":"JVYnDJRLbNcv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1597319903462,"user_tz":-540,"elapsed":559362,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"513782cf-ea38-4697-cbb4-038ed8902615"},"source":["model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=10, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='softmax'))\n","\n","criterion = lambda x, y : tf.keras.backend.mean(tf.keras.losses.categorical_crossentropy(x, y, from_logits=False))\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n","\n","for epoch in range(training_epochs):\n","  avg_cost = 0\n","  total_batch = len(x_train) // batch_size\n","\n","  for i, (batch_xs, batch_ys) in enumerate(data_train): \n","    with tf.GradientTape() as tape:\n","      hypothesis = model(batch_xs, training=True)\n","      cost = tf.keras.backend.mean(criterion(batch_ys, hypothesis)) \n","    grads = tape.gradient(cost, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","    \n","    avg_cost += cost / total_batch\n","\n","  print(\"[Epoch: %7d] cost = %5.5f\"%(epoch + 1, avg_cost))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[Epoch:       1] cost = 12.92622\n","[Epoch:       2] cost = 13.92229\n","[Epoch:       3] cost = 14.30269\n","[Epoch:       4] cost = 14.30322\n","[Epoch:       5] cost = 14.30376\n","[Epoch:       6] cost = 14.30323\n","[Epoch:       7] cost = 14.00320\n","[Epoch:       8] cost = 14.08859\n","[Epoch:       9] cost = 13.94928\n","[Epoch:      10] cost = 12.82328\n","[Epoch:      11] cost = 12.81979\n","[Epoch:      12] cost = 12.81952\n","[Epoch:      13] cost = 12.82301\n","[Epoch:      14] cost = 12.82463\n","[Epoch:      15] cost = 12.82113\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"srLIP9E7cZBm","colab_type":"text"},"source":["학습결과를 확인해본다."]},{"cell_type":"code","metadata":{"id":"iQZeFXVRcb-J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597319904050,"user_tz":-540,"elapsed":559929,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"2594190c-f1a1-429e-d9fa-2419efb5a402"},"source":["hypothesis = model(x_test, training=False)\n","correct_prediction = tf.keras.backend.equal(tf.keras.backend.argmax(hypothesis, 1), tf.keras.backend.argmax(y_test, 1))\n","accuracy = tf.keras.backend.mean(tf.cast(correct_prediction, tf.float32))\n","print('Accuracy:', accuracy.numpy())"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Accuracy: 0.2092\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Sc3RUULNco4z","colab_type":"text"},"source":["엄청난 차이가 있음을 알 수 있다.\n","\n","대체 무슨 차이가 있을까 내부를 뜯어봤더니\n","\n","**로짓을 입력으로 받는 cross_entropy_with_logit 계열 함수들이 확률을 입력으로 받는 cross_entropy 계열 함수들보다 수치적으로 안정적(numerically unstable)이라는 사실을 알아냈다.**\n","\n","아래는 함수들이 확률을 입력으로 받는 cross_entropy 계열 함수의 수식이다.\n","\n","# -sum(label * log(probability))\n","\n","이 수식의 경우 probability가 0일 경우에 log(0)이 되서 NaN이 뜰 확률이 높다.\n","\n","근데 로짓을 입력으로 받는 cross_entropy_with_logit 계열 함수들은 이렇게 생겼고\n","\n","# -sum(label * log(exp(logit) / sum(exp(logit))))\n","\n","log(0)를 근본적으로 피할 수 있게 아래와 같이 reform이 가능하다.\n","\n","# = -sum(label * log(exp(logit) / sum(exp(logit))))\n","# = -sum(label * (log(exp(logit)) - log(sum(exp(logit)))))\n","# = -sum(label * (logit - log(sum(exp(logit)))))\n","\n","실제로 텐서플로우 API가 이런식으로 구현되어 있다.\n","https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/xent_op.h?fbclid=IwAR0WBkHGDgz9NfzuwbXyza68djTouOxaCraG1jfXDeh8MetZ3InvVbkGXos#L35\n","\n","따라서 마지막 레이어의 activation을 'softmax'대신 None으로 놓고\n","\n","tf.keras.losses.categorical_crossentropy의 from_logits 인자를 True로 놓으면 안정적인 학습이 가능함을 알 수 있다."]},{"cell_type":"code","metadata":{"id":"KpGj79n8fB90","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1597320252085,"user_tz":-540,"elapsed":907943,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"8ab337fc-7ee3-43bd-b7c5-46b3a53f1b97"},"source":["(x_train, y_train), (x_test, y_test) = load_data()\n","\n","x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n","x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n","\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","\n","data_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n","\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","##############################################################바뀐 부분#####################################################################\n","model.add(tf.keras.layers.Dense(units=10, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation=None))\n","\n","criterion = lambda x, y : tf.keras.backend.mean(tf.keras.losses.categorical_crossentropy(x, y, from_logits=True))\n","############################################################################################################################################\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n","\n","for epoch in range(training_epochs):\n","  avg_cost = 0\n","  total_batch = len(x_train) // batch_size\n","\n","  for i, (batch_xs, batch_ys) in enumerate(data_train): \n","    with tf.GradientTape() as tape:\n","      hypothesis = model(batch_xs, training=True)\n","      cost = tf.keras.backend.mean(criterion(batch_ys, hypothesis)) \n","    grads = tape.gradient(cost, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","    \n","    avg_cost += cost / total_batch\n","\n","  print(\"[Epoch: %7d] cost = %5.5f\"%(epoch + 1, avg_cost))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["[Epoch:       1] cost = 3.10352\n","[Epoch:       2] cost = 0.43175\n","[Epoch:       3] cost = 0.31126\n","[Epoch:       4] cost = 0.25589\n","[Epoch:       5] cost = 0.22204\n","[Epoch:       6] cost = 0.20632\n","[Epoch:       7] cost = 0.19979\n","[Epoch:       8] cost = 0.18638\n","[Epoch:       9] cost = 0.18818\n","[Epoch:      10] cost = 0.18887\n","[Epoch:      11] cost = 0.18071\n","[Epoch:      12] cost = 0.18631\n","[Epoch:      13] cost = 0.17571\n","[Epoch:      14] cost = 0.17700\n","[Epoch:      15] cost = 0.16782\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gf4E4gKcfdp1","colab_type":"text"},"source":["안정적으로 학습되는 모습을 확인했으면 정확도도 확인해보자"]},{"cell_type":"code","metadata":{"id":"96MeoRNQfiGc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597320252735,"user_tz":-540,"elapsed":908572,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"6a5cfc93-f987-43cb-f201-ddadd6418640"},"source":["hypothesis = model(x_test, training=False)\n","correct_prediction = tf.keras.backend.equal(tf.keras.backend.argmax(hypothesis, 1), tf.keras.backend.argmax(y_test, 1))\n","accuracy = tf.keras.backend.mean(tf.cast(correct_prediction, tf.float32))\n","print('Accuracy:', accuracy.numpy())"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Accuracy: 0.9701\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nnGceQnNflIn","colab_type":"text"},"source":["'model.compile', 'model.fit'을 이용한 코드와 거의 동일한 성능을 냄을 알 수 있다.\n","\n","그렇다면 왜 'model.compile', 'model.fit'을 이용한 코드는 확률을 입력으로 받는 cross_entropy 계열 함수를 써도 안정적인 학습이 가능할까?\n","\n","아마도 model.compile 함수 내부에서 전체 그래프를 컴파일하는 과정에서 이러한 부분을 자동으로 Reformulation 해주는 것으로 보인다.\n","\n","실제로 'model.compile', 'model.fit'을 이용한 코드의 마지막 레이어의 activation을 'softmax'대신 None으로 놓고,\n","\n","로스 함수를 키워드로 불러오지 않고(키워드로 불러오면 from_logits 인자가 False로 설정됨) tf.keras.losses.categorical_crossentropy로 불러오면서 from_logits 인자를 True로 놓으면 원본과 학습결과가 별로 달라지지 않음을 알 수 있다."]},{"cell_type":"code","metadata":{"id":"Y9tqCbN5hMwr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":598},"executionInfo":{"status":"ok","timestamp":1597320461527,"user_tz":-540,"elapsed":1117343,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"afc4ce9f-d675-47fb-ba87-b346fabd7b96"},"source":["(x_train, y_train), (x_test, y_test) = load_data()\n","\n","x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n","x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n","\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=10, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation=None))\n","\n","model.compile(loss=lambda x, y : tf.keras.backend.mean(tf.keras.losses.categorical_crossentropy(x, y, from_logits=True)) ,\n","                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)\n","\n","evaluation = model.evaluate(x_test, y_test)\n","print('loss: ', evaluation[0])\n","print('accuracy', evaluation[1])"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","600/600 [==============================] - 14s 24ms/step - loss: 3.1609 - accuracy: 0.7393\n","Epoch 2/15\n","600/600 [==============================] - 13s 22ms/step - loss: 0.4348 - accuracy: 0.8783\n","Epoch 3/15\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3077 - accuracy: 0.9131\n","Epoch 4/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.2515 - accuracy: 0.9297\n","Epoch 5/15\n","600/600 [==============================] - 15s 24ms/step - loss: 0.2133 - accuracy: 0.9407\n","Epoch 6/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.1957 - accuracy: 0.9464\n","Epoch 7/15\n","600/600 [==============================] - 13s 22ms/step - loss: 0.1973 - accuracy: 0.9473\n","Epoch 8/15\n","600/600 [==============================] - 13s 22ms/step - loss: 0.1853 - accuracy: 0.9505\n","Epoch 9/15\n","600/600 [==============================] - 13s 22ms/step - loss: 0.1825 - accuracy: 0.9533\n","Epoch 10/15\n","600/600 [==============================] - 14s 24ms/step - loss: 0.1844 - accuracy: 0.9535\n","Epoch 11/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.1802 - accuracy: 0.9550\n","Epoch 12/15\n","600/600 [==============================] - 15s 25ms/step - loss: 0.1825 - accuracy: 0.9563\n","Epoch 13/15\n","600/600 [==============================] - 14s 23ms/step - loss: 0.1849 - accuracy: 0.9559\n","Epoch 14/15\n","600/600 [==============================] - 13s 22ms/step - loss: 0.1628 - accuracy: 0.9602\n","Epoch 15/15\n","600/600 [==============================] - 13s 22ms/step - loss: 0.1756 - accuracy: 0.9587\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1303 - accuracy: 0.9725\n","loss:  0.13028447329998016\n","accuracy 0.9725000262260437\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"saVjP-gViHuR","colab_type":"text"},"source":["정리하자면\n","\n","1. 로짓을 입력으로 받는 cross_entropy_with_logit 계열 함수들이 확률을 입력으로 받는 cross_entropy 계열 함수들보다 수치적으로 안정적이다.\n","2. model.compile API는 둘 중 뭘 써도 알아서 안정적으로 바꿔준다.\n","3. 하지만 커스텀 루프는 사용자가 코딩해놓은 대로 정직하게(?) 동작하기 때문에 마지막 레이어의 activation을 softmax대신 None으로 해놓고 cross_entropy_with_logit을 사용해야 안정적으로 작동한다."]}]}